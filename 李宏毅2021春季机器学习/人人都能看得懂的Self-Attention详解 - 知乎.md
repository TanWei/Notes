最近死磕self-attetion，终于算是入门了，接下来从我的角度说一下我对它的理解。附上transformer原文链接[https://arxiv.org/pdf/1706.03762.pdf](https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1706.03762.pdf)

**1.背景**

**2.作用**

**3.权重计算**

**4.QKV的计算**

**5.多头**

**1.背景**  

-----------

![](https://pic2.zhimg.com/v2-5e50b201c1794a49627162ecb88f3fe1_b.jpg)
![](https://pic3.zhimg.com/v2-e69867e51d96fc59e773044e8e177eda_b.jpg)
![](https://pic3.zhimg.com/v2-dec46b444d0c6a0f33e4a7eae1dd5aae_b.jpg)
![](https://pic2.zhimg.com/v2-50e836d1cc26bfcfd202f20e0b6aa875_b.jpg)

简单来说就是RNN难以处理长序列的句子，计算时面临对齐问题，无法实现并行（每个时间步的输出需要依赖于前面时间步的输出，这使得模型没有办法并行）。【并行问题&长期依赖问题面临梯度消失/爆炸】

CNN不能直接用于处理变长的序列样本但可以实现并行计算。完全基于CNN的Seq2Seq模型虽然可以并行实现，但非常占内存，很多的trick，大数据量上参数调整并不容易。【长期依赖问题&调参问题】

而Self-Attention允许对依赖关系建模，而不需要考虑它们在输入或输出序列中的距离，并且可以将一个序列的不同位置串联起来。最重要的是有一些网络证明Self-Attention效果确实如上所说。

**2.作用**
--------

说到底Self-Attention的作用就是全局关联权重，然后做输入的加权和。

例如我有三个词 A B C ，首先将ABC编码成向量， 然后进Attention层， 然后对ABC分别洗脑，告诉你其他两个词对你也很重要，你的心里要有他们，就这样每个词的重组就是给自己一点权重（最多），给其他两个人一点权重，然后组合成新的自己。例如

![](https://pic1.zhimg.com/v2-336376342a8d1ae94076a49f580a5474_b.jpg)

所以现在的问题就是每个词重构时都会与自己本身、其他词产生一个权重。

每个词之间的权重是如何产生的。

**3.权重的产生**
-----------

(这里直接贴出知乎大佬JayLou的知识贴，减少不必要的工作量。）

![](https://pic1.zhimg.com/v2-f425879681d4d09226279b569dd0f51c_b.jpg)

我来简述一下，注意力核心是算权重系数，权重系数的计算如下4种方式，但套路差不多。主要为：

1）计算相似度

2）进softmax函数归一化出权重系数

关于相似度的理解与计算，从几何角度就是计算向量的内积，值越高，投影越大，也就越相似。关于此处的理解建议看这篇博文[超详细图解Self-Attention的那些事儿](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI5MDUyMDIxNA%3D%3D%26mid%3D2247579430%26idx%3D1%26sn%3D3c63a42410e2107f1f91f861dc25c3cb%26scene%3D21%23wechat_redirect)

理解了权重计算公式， 我们看看到底各个向量之间是如何计算权重的

**4.** **QKV的计算**
-----------------

而在**Transformer**中使用的是第三种。也就是文中的**scaled** **dot** **product**

![](https://pic3.zhimg.com/v2-76030bd1303a6728c0357a7d1566b66e_b.jpg)

QKV是qkv的矩阵形式， 所以本质是搞清楚qkv是干嘛的；

在self-attention中，q、k、v都是输入参数矩阵变换而来的(增加可学习性)

其中q和k是算相似度的得权重的，v是用来跟权重做加权求和的；（看下图，宏观上的步骤理解，忽略Mask模块）  

![](https://pic3.zhimg.com/v2-bea4e5d4214409ba908ef9d1e2c7b902_b.jpg)

然后多个向量之间怎么互相求权重呢？

![](https://pic4.zhimg.com/v2-e592c14cc8cd5d7391e78f5576097ac7_b.jpg)

上图解释的清清楚楚；

现在有4个输入a1 a2 a3 a4

四个输入分别线性变换得到各自的qi ki vi  

当重新计算a1时步骤如下：

将ai的查询向量q与四个k计算，求权重，然后在做线性相加就得到输出b1；

此时的b1真的考虑了所有人的，不再只关注自己；是个好男人

其他的输入a2 a3 a4 同理对自己进行改造  

![](https://pic2.zhimg.com/v2-47a6cb5d0bf6808244cabea67b49c2f5_b.jpg)

然后qi对k1到k4的权重可以组成一个矩阵Q。同理最终，k，v也可以用矩阵的形式表达， 就变成了QKV的矩阵表现形式，方便进行并行计算。

![](https://pic2.zhimg.com/v2-ac29f6ba748b1bf45f1c0578ebcbe1d1_b.jpg)

至此，关于self-Attention计算的来龙去脉，也就从逻辑上梳理清楚了；

由此我们也能理解self-attention它每一个输入，经过attention层都是跟其他输入建立了联系的，所以这也是self-attention层是能够全局地提取到整个序列信息的原因。（每个人对自己和其他人的出轨记录卦都掌握的一种感觉，受力宏影响太大了。。。。。。。）

**5.** **Multi-head** **Attention**
-----------------------------------

![](https://pic4.zhimg.com/v2-40e5384817ff93d6ee1bdbce88ebda0f_b.jpg)

最初真的是理解有误，导致自闭了，论文的讲解真的是太简略了，自己在那瞎猜。最初我以为是将一个词--长512的向量分成n个头，然后互相之间做self-attention，最后concat； 其实做是可以做，但是违背了self-attention掌握自己和其他人信息的初衷

**1）逻辑**

例如还是a1 a2 a3 a4四个输入向量，长度是512；上一节是一个头；

那多个头就是将四个输入向量的长度一分为N段，各自对应的部分做self-attention，每个向量再聚合分段的结果。如下图

![](https://pic4.zhimg.com/v2-3fb6aaf6f842beed89e2d28ec81990af_b.jpg)
![](https://pic4.zhimg.com/v2-247211a5cfbbe24830174b7e143886f7_b.jpg)

**2）权重计算**

还是关于qkv的计算逻辑；

既然分头/分段了， 那就是**分完段，各自算，再汇总**， head1的qkv算head1的， 头与头之间在计算相似度时互不打扰， 每个段独立算完，再聚合

李宏毅ppt：粗看有点晕，但其实就是我总结的那句话

![](https://pic4.zhimg.com/v2-36292ad3931dd39075b4e2c88285d817_b.jpg)

**3）多头的目的**

**简单讲：多样性**  

我们发现QKV都是通过乘参数矩阵W而来的，一个头就只有一个学习空间；多个头就有多个学习空间，可能学习的东西会多一点，不会别带跑偏；

官方一点的说法：  
这种结构设计能让每个注意力机制通过QKV映射到不同的空间去学习特征，去优化每个词汇的不同特征部分，从而均衡同一种注意力机制可能产生的偏差，让词义拥有来自更多元的表达，实验表明可以从而提升模型效果.

以上就是我对self-attention以及multi-head attentoin在逻辑端的理解，理解了逻辑，才能更好的理解其在数据端的使用。

不知不觉码了接近三个小时，也算记录了自己对它的理解，后续温故知新  

如果有问题，欢迎指正。 欢迎关注我的公众号：Cv打怪升级 一起学习交流